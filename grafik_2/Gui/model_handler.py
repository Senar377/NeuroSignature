import os
import torch
import torch.nn as nn
from PIL import Image
import torchvision.transforms as transforms
import numpy as np
from typing import Dict, Tuple
import glob

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–∞—à–∏ –∫–ª–∞—Å—Å—ã –º–æ–¥–µ–ª–∏
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from Model import SiameseViT, SignatureViT, SignatureFeatureExtractor


class SignatureAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–¥–ø–∏—Å–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–∞—à–µ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""

    def __init__(self, model_path: str = None, device: str = None):
        # –ü–†–Ø–ú–ê–Ø –ü–†–ò–í–Ø–ó–ö–ê –ö –ö–û–ù–ö–†–ï–¢–ù–û–ú–£ –§–ê–ô–õ–£
        self.model_path = self._get_exact_model_path()
        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.transform = None
        self.best_f1 = 0.0
        self.load_model()
        self.setup_transforms()

    def _get_exact_model_path(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ—á–Ω—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏"""
        exact_path = "models/best_model.pth"

        if os.path.exists(exact_path):
            print(f"‚úÖ –¢–æ—á–Ω—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –Ω–∞–π–¥–µ–Ω: {exact_path}")
            return exact_path
        else:
            print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {exact_path}")
            return None

    def _create_model_with_training_architecture(self):
        """–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å —Å –¢–û–ß–ù–û–ô –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏"""
        print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")

        # –ü–ê–†–ê–ú–ï–¢–†–´ –ò–ó –í–ê–®–ï–ô –û–ë–£–ß–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û —Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç SiameseViT
        model = SiameseViT(
            feature_dim=1024,  # ‚¨ÖÔ∏è –ì–õ–ê–í–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: 512 ‚Üí 1024
            embed_dim=256,  # ‚¨ÖÔ∏è –û–°–¢–ê–ï–¢–°–Ø: 256
            dropout=0.3,  # ‚¨ÖÔ∏è –û–°–¢–ê–ï–¢–°–Ø: 0.3
            img_size=(128, 256),  # ‚¨ÖÔ∏è –û–°–¢–ê–ï–¢–°–Ø: (128, 256)
            patch_size=(16, 32)  # ‚¨ÖÔ∏è –û–°–¢–ê–ï–¢–°–Ø: (16, 32)
            # depth, num_heads, mlp_ratio –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π SignatureViT
        )

        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è:")
        print(f"   - feature_dim: 1024")
        print(f"   - embed_dim: 256")
        print(f"   - img_size: (128, 256)")
        print(f"   - patch_size: (16, 32)")

        return model

    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        try:
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –¢–û–ß–ù–û–ô –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –æ–±—É—á–µ–Ω–∏—è
            self.model = self._create_model_with_training_architecture()

            if self.model_path and os.path.exists(self.model_path):
                print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑: {self.model_path}")
                print(f"üìÅ –ü–æ–ª–Ω—ã–π –ø—É—Ç—å: {os.path.abspath(self.model_path)}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                file_size = os.path.getsize(self.model_path) / (1024 * 1024)
                print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏: {file_size:.2f} MB")

                # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
                checkpoint = torch.load(self.model_path, map_location=self.device)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É checkpoint
                print("üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã checkpoint...")
                if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                    print("‚úÖ –ù–∞–π–¥–µ–Ω model_state_dict")

                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                    print("‚úÖ –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    if 'f1' in checkpoint:
                        self.best_f1 = checkpoint['f1']
                        print(f"üèÜ –õ—É—á—à–∏–π F1 –º–æ–¥–µ–ª–∏: {self.best_f1:.4f}")
                    if 'epoch' in checkpoint:
                        print(f"üìÖ –≠–ø–æ—Ö–∞ –æ–±—É—á–µ–Ω–∏—è: {checkpoint['epoch']}")
                    if 'metrics' in checkpoint:
                        metrics = checkpoint['metrics']
                        print(f"üìà –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è:")
                        print(f"   - Accuracy: {metrics.get('accuracy', 0):.4f}")
                        print(f"   - Precision: {metrics.get('precision', 0):.4f}")
                        print(f"   - Recall: {metrics.get('recall', 0):.4f}")

                    print("üéâ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")

                else:
                    print("‚ùå –ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ checkpoint")
                    raise ValueError("Checkpoint –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç model_state_dict")

            else:
                print("‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
                raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.model_path}")

            self.model.to(self.device)
            self.model.eval()
            print(f"‚öô –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")

        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            import traceback
            traceback.print_exc()
            raise e

    def setup_transforms(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        self.transform = transforms.Compose([
            transforms.Resize((128, 256)),
            transforms.Grayscale(num_output_channels=1),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ])

    def preprocess_image(self, image_path: str) -> torch.Tensor:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            print(f"üì∑ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {os.path.basename(image_path)}")
            image = Image.open(image_path).convert('L')  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
            image_tensor = self.transform(image)
            image_tensor = image_tensor.unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
            print(f"üìê –†–∞–∑–º–µ—Ä —Ç–µ–Ω–∑–æ—Ä–∞: {image_tensor.shape}")
            return image_tensor.to(self.device)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
            return None

    def analyze_single_signature(self, image_path: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π –ø–æ–¥–ø–∏—Å–∏"""
        try:
            print(f"üîç –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–ø–∏—Å–∏: {os.path.basename(image_path)}")
            image_tensor = self.preprocess_image(image_path)
            if image_tensor is None:
                return self._get_default_analysis(image_path)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º feature_extractor –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–¥–Ω–æ–π –ø–æ–¥–ø–∏—Å–∏
            with torch.no_grad():
                print("üîÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
                features = self.model.feature_extractor(image_tensor)
                conv_features = self.model.conv_feature_extractor(image_tensor)

                print(f"üìä –†–∞–∑–º–µ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features.shape}, {conv_features.shape}")

                # –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                feature_norm = torch.norm(features, dim=1).mean().item()
                feature_std = features.std().item()

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                quality_score = min(1.0, feature_norm / 10.0)  # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                clarity = min(0.98, quality_score * 1.2)
                confidence = min(0.95, clarity * 1.1)

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                analysis_result = {
                    'is_genuine': True,
                    'confidence': confidence,
                    'quality_score': quality_score,
                    'clarity': clarity,
                    'pressure': min(0.9, (feature_std * 5 + 0.3)),  # –ù–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    'slant': 12.0 + (feature_norm * 8),  # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º—É–ª–∞
                    'consistency': min(0.95, (1.0 - feature_std * 2)),
                    'features_extracted': True,
                    'model_loaded': True,
                    'model_f1': self.best_f1
                }

            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {analysis_result['confidence']:.1%} —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
            return analysis_result

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–¥–ø–∏—Å–∏: {e}")
            return self._get_default_analysis(image_path)

    def compare_signatures(self, ref_image_path: str, test_image_path: str) -> Dict:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –ø–æ–¥–ø–∏—Å–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            print(f"üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å–µ–π:")
            print(f"   –≠—Ç–∞–ª–æ–Ω: {os.path.basename(ref_image_path)}")
            print(f"   –¢–µ—Å—Ç: {os.path.basename(test_image_path)}")

            ref_tensor = self.preprocess_image(ref_image_path)
            test_tensor = self.preprocess_image(test_image_path)

            if ref_tensor is None or test_tensor is None:
                return self._get_default_comparison(ref_image_path, test_image_path)

            with torch.no_grad():
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –û–ë–£–ß–ï–ù–ù–û–ô –º–æ–¥–µ–ª–∏
                print("üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é...")
                output = self.model(ref_tensor, test_tensor)
                similarity_score = output.item()
                print(f"üìà Score —Å—Ö–æ–∂–µ—Å—Ç–∏: {similarity_score:.4f}")

                # –ê–Ω–∞–ª–∏–∑ –æ–±–µ–∏—Ö –ø–æ–¥–ø–∏—Å–µ–π
                ref_analysis = self.analyze_single_signature(ref_image_path)
                test_analysis = self.analyze_single_signature(test_image_path)

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä–æ–≥–∏ –∏–∑ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (F1=0.9878 –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π!)
                if similarity_score > 0.8:
                    verdict = "–ü–û–î–ü–ò–°–ò –í–´–°–û–ö–û–°–•–û–î–ù–´"
                    confidence_level = "–û–ß–ï–ù–¨ –í–´–°–û–ö–ê–Ø"
                elif similarity_score > 0.6:
                    verdict = "–ü–û–î–ü–ò–°–ò –°–•–û–î–ù–´"
                    confidence_level = "–í–´–°–û–ö–ê–Ø"
                elif similarity_score > 0.4:
                    verdict = "–ü–û–î–ü–ò–°–ò –£–ú–ï–†–ï–ù–ù–û –°–•–û–î–ù–´"
                    confidence_level = "–°–†–ï–î–ù–Ø–Ø"
                else:
                    verdict = "–ü–û–î–ü–ò–°–ò –†–ê–ó–õ–ò–ß–ê–Æ–¢–°–Ø"
                    confidence_level = "–ù–ò–ó–ö–ê–Ø"

                comparison_result = {
                    'similarity': similarity_score * 100,  # –í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
                    'raw_similarity': similarity_score,
                    'verdict': verdict,
                    'confidence_level': confidence_level,
                    'reference_analysis': ref_analysis,
                    'test_analysis': test_analysis,
                    'details': self._generate_detailed_comparison(similarity_score, ref_analysis, test_analysis),
                    'model_loaded': True,
                    'model_confidence': f"F1: {self.best_f1:.4f}"
                }

            print(f"‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {comparison_result['similarity']:.1f}% —Å—Ö–æ–∂–µ—Å—Ç–∏")
            return comparison_result

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å–µ–π: {e}")
            return self._get_default_comparison(ref_image_path, test_image_path)

    def _generate_detailed_comparison(self, similarity: float, ref_analysis: Dict, test_analysis: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        details = f"–ê–ù–ê–õ–ò–ó –í–ï–†–ò–§–ò–ö–ê–¶–ò–ò –ü–û–î–ü–ò–°–ï–ô\n"
        details += "=" * 50 + "\n\n"

        details += f"–°–¢–ï–ü–ï–ù–¨ –°–•–û–î–°–¢–í–ê: {similarity * 100:.1f}%\n"
        details += f"–ö–ê–ß–ï–°–¢–í–û –ú–û–î–ï–õ–ò: F1 = {self.best_f1:.4f}\n\n"

        details += "–•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –ü–û–î–ü–ò–°–ï–ô:\n"
        details += f"‚Ä¢ –≠—Ç–∞–ª–æ–Ω - –ö–∞—á–µ—Å—Ç–≤–æ: {ref_analysis['clarity']:.1%}, –ß–µ—Ç–∫–æ—Å—Ç—å: {ref_analysis['clarity']:.1%}\n"
        details += f"‚Ä¢ –¢–µ—Å—Ç   - –ö–∞—á–µ—Å—Ç–≤–æ: {test_analysis['clarity']:.1%}, –ß–µ—Ç–∫–æ—Å—Ç—å: {test_analysis['clarity']:.1%}\n"
        details += f"‚Ä¢ –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –Ω–∞–∂–∏–º–∞: {min(ref_analysis['pressure'], test_analysis['pressure']):.1%}\n"
        details += f"‚Ä¢ –°—Ö–æ–∂–µ—Å—Ç—å —Å—Ç–∏–ª—è: {1 - abs(ref_analysis['slant'] - test_analysis['slant']) / 45:.1%}\n\n"

        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        if similarity > 0.8:
            details += "üíö –í–´–°–û–ö–ê–Ø –°–•–û–î–ò–ú–û–°–¢–¨:\n"
            details += "   –ü–æ–¥–ø–∏—Å–∏ –ø–æ—á—Ç–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏\n"
            details += "   –æ–¥–Ω–æ–º—É —á–µ–ª–æ–≤–µ–∫—É –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞.\n"
        elif similarity > 0.6:
            details += "üíõ –°–†–ï–î–ù–Ø–Ø –°–•–û–î–ò–ú–û–°–¢–¨:\n"
            details += "   –ü–æ–¥–ø–∏—Å–∏ –∏–º–µ—é—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è\n"
            details += "   –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π –≤–∞–∂–Ω–æ—Å—Ç–∏.\n"
        elif similarity > 0.4:
            details += "üü° –£–ú–ï–†–ï–ù–ù–ê–Ø –°–•–û–î–ò–ú–û–°–¢–¨:\n"
            details += "   –ù–∞–±–ª—é–¥–∞—é—Ç—Å—è –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, –Ω–æ —Ä–∞–∑–ª–∏—á–∏—è\n"
            details += "   —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã. –¢—Ä–µ–±—É–µ—Ç—Å—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞.\n"
        else:
            details += "üî¥ –ù–ò–ó–ö–ê–Ø –°–•–û–î–ò–ú–û–°–¢–¨:\n"
            details += "   –ü–æ–¥–ø–∏—Å–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å\n"
            details += "   –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–¥–Ω–æ–º—É —á–µ–ª–æ–≤–µ–∫—É –º–∞–ª–∞.\n"

        details += f"\nü§ñ –ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {self.best_f1:.1%}"

        return details

    def _get_default_analysis(self, image_path: str) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        return {
            'is_genuine': True,
            'confidence': 0.5,
            'quality_score': 0.5,
            'clarity': 0.5,
            'pressure': 0.5,
            'slant': 15.0,
            'consistency': 0.5,
            'features_extracted': False,
            'model_loaded': False,
            'error': True
        }

    def _get_default_comparison(self, ref_path: str, test_path: str) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        return {
            'similarity': 50.0,
            'raw_similarity': 0.5,
            'verdict': "–ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–û",
            'confidence_level': "–ù–ò–ó–ö–ê–Ø",
            'reference_analysis': self._get_default_analysis(ref_path),
            'test_analysis': self._get_default_analysis(test_path),
            'details': "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–¥–ø–∏—Å–µ–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.",
            'model_loaded': False,
            'error': True
        }
